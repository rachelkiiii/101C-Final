import pandas as pd
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import time
import os
from sklearn.preprocessing import MinMaxScaler
from gensim.models import CoherenceModel

# Load or create your DataFrame as needed
# Assuming df is your DataFrame

# Read positive and negative words from text files

start = time.time()
df = pd.read_csv("~/Downloads/cleandata.csv")

start = time.time()

# Get the expanded home directory
home_directory = os.path.expanduser('~')

# Specify the file paths using the expanded home directory
positive_file_path = os.path.join(home_directory, 'Downloads', 'positive-words.txt')
negative_file_path = os.path.join(home_directory, 'Downloads', 'negative-words.txt')

# Read positive words from positive-words.txt
with open(positive_file_path, 'r') as file:
    positive_words = file.read().splitlines()

with open(negative_file_path, 'r') as file:
    negative_words = set(file.read().splitlines())



# Split the dataset into training and testing sets
train_data, test_data, train_labels, test_labels = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)

# Apply TF-IDF transformation
tfidf_vectorizer = TfidfVectorizer(min_df=0.1, max_df=0.7, max_features=5000)
tfidf_matrix_train = tfidf_vectorizer.fit_transform(train_data)
tfidf_matrix_test = tfidf_vectorizer.transform(test_data)

# Normalize TF-IDF features
scaler = StandardScaler(with_mean=False)
tfidf_matrix_train_normalized = scaler.fit_transform(tfidf_matrix_train)
tfidf_matrix_test_normalized = scaler.transform(tfidf_matrix_test)


# Add sentiment lexicon features
sentiment_lexicon_train = pd.DataFrame(columns=['positive', 'negative'], index=train_data.index)
sentiment_lexicon_test = pd.DataFrame(columns=['positive', 'negative'], index=test_data.index)

  
for i, tokens in enumerate(train_data):
    
    sentiment_lexicon_train.loc[train_data.index[i], 'positive'] = sum(1 for word in tokens.split() if word.replace("'", "").replace(",", "").replace("[", "").replace("]", "") in positive_words)
    sentiment_lexicon_train.loc[train_data.index[i], 'negative'] = sum(1 for word in tokens.split() if word.replace("'", "").replace(",", "").replace("[", "").replace("]", "") in negative_words)

for i, tokens in enumerate(test_data):
    sentiment_lexicon_test.loc[test_data.index[i], 'positive'] = sum(1 for word in tokens.split() if word.replace("'", "").replace(",", "").replace("[", "").replace("]", "") in positive_words)
    sentiment_lexicon_test.loc[test_data.index[i], 'negative'] = sum(1 for word in tokens.split() if word.replace("'", "").replace(",", "").replace("[", "").replace("]", "") in negative_words)



# Concatenate TF-IDF matrix with sentiment lexicon features
X_train = pd.concat([pd.DataFrame(tfidf_matrix_train_normalized.toarray(), index=train_data.index), sentiment_lexicon_train], axis=1)
X_test = pd.concat([pd.DataFrame(tfidf_matrix_test_normalized.toarray(), index=test_data.index), sentiment_lexicon_test], axis=1)

X_train.columns = X_train.columns.astype(str)
X_test.columns = X_test.columns.astype(str)

# Get the minimum of the number of samples and features
min_samples_features = min(X_train.shape[0], X_train.shape[1])

# Set n_components to be less than or equal to the minimum
n_components = min(100, min_samples_features)  # You can adjust the maximum value as needed

# Apply PCA
pca = PCA(n_components=n_components)
X_train_pca = pca.fit_transform(X_train)
X_test_pca = pca.transform(X_test)

# Scale PCA-transformed data to ensure non-negativity
scaler = MinMaxScaler()
X_train_pca_scaled = scaler.fit_transform(X_train_pca)
X_test_pca_scaled = scaler.transform(X_test_pca)

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support


# Split the PCA-transformed and scaled data into training and testing sets
X_train_final, X_test_final = X_train_pca_scaled, X_test_pca_scaled

# Initialize Linear Discriminant Analysis (LDA) model
lda = LinearDiscriminantAnalysis()

# Fit the LDA model on training data
lda.fit(X_train_final, train_labels)

# Predictions on the test set
predictions = lda.predict(X_test_final)

# Evaluate the classification performance
report = classification_report(test_labels, predictions, target_names=['False', 'True'], output_dict=True, zero_division=1)
accuracy = accuracy_score(test_labels, predictions)

# Print the classification report
print("Precision\tRecall\tF1-Score\tSupport")
for label in ['False', 'True']:
    precision = report[label]['precision']
    recall = report[label]['recall']
    f1_score = report[label]['f1-score']
    support = report[label]['support']
    print(f"{label}\t{precision:.4f}\t{recall:.4f}\t{f1_score:.4f}\t{support}")

# Print overall accuracy
print(f"\nAccuracy: {accuracy:.4f}")

# Print macro and weighted averages
macro_avg = report['macro avg']
weighted_avg = report['weighted avg']
print("\nMacro Avg\t{:.4f}\t{:.4f}\t{:.4f}\t{:.0f}".format(macro_avg['precision'], macro_avg['recall'], macro_avg['f1-score'], macro_avg['support']))
print("Weighted Avg\t{:.4f}\t{:.4f}\t{:.4f}\t{:.0f}".format(weighted_avg['precision'], weighted_avg['recall'], weighted_avg['f1-score'], weighted_avg['support']))


# Convert categorical labels to binary labels
test_labels_binary = test_labels.replace({'negative': 0, 'positive': 1})

# Predict the probability scores for the positive class
y_scores = lda.predict_proba(X_test_final)[:, 1]


end = time.time()

elapsed_time = end-start
print(elapsed_time)

# Compute ROC curve and AUC
fpr, tpr, thresholds = roc_curve(test_labels_binary, y_scores)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(8, 8))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = {:.2f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()
